# -*- coding: utf-8 -*-
"""regressao_logistica_churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IBmxp6NPqxa7jhdCiBVo33w8CtSyJ2vC
"""

#Bibliotecas
!git clone https://github.com/FelipeFernandes1/minhas_funcoes
from minhas_funcoes.pacote_aed import *
from IPython.display import display
pd.set_option('display.max_colwidth', None)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import roc_auc_score
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, StratifiedKFold

"""# Enquadrando o problema

## Contexto

O aplicativo ToComFome é um app de entrega de comida por delivery. Como todo aplicativo de varejo, a empresa se preocupa com o Churn de clientes, ou seja, da perda desse cliente para a concorrência. Para entender o perfil de risco do cliente com maior chance de churn, a área de CRM pediu um projeto para a área de Data Analytics para entender e classificar o cliente com risco de trocar de aplicativo nos próximos meses.

Para isso, a área de CRM passou uma amostra de cerca de 10 mil clientes com suas respectivas informações de cadastro e transações nos próximos 4 meses a contar da data de extração usada como referência.

##Proposta de solução

Criar um modelo preditivo capaz de classificar o usuário antes de apresentar o churn, para que seja possível agir antecipadamente de forma a retê-lo, utilizando a estratégia de cupons de desconto.

## Objetivos

1 - Criar um modelo de classificação

2 - Mensurar o potencial financeiro do modelo proposto

## <font color="yellow">Premissas

- Trata-se de uma amostra sem viés
- O churn é definido pelo fato da falta de transações nos últimos 30 dias, tendo como referência o último dia do período de 4 meses
- Ao receber um cupom de desconto, o cliente irá utilizá-lo e isso será o suficiente para retê-lo
- Para o próximo período o usuário manterá seu padrão de volume nas compras(Sum_Pedidos_Acumulados)
- Variáveis relacionadas ao crédito dos usuários foram adquiridas através de um bureau de crédito
- Por haver apenas uma data de extração, não será possível realizar a validação do modelo considerando a ordem cronológica(validação out of time)
- O tamanho(pequeno) do conjunto de dados não é o ideal para o aprendizado de máquina
- Para realizar o cálculo do potencial financeiro foi necessário assumir alguns valores(no mundo real essa informação poderia ser fornecida pelo time de Marketing):
LTV= média da variável "Sum_Pedidos_Acumulados"; CAC= 150; Custo cupom= 100
- Cálculo para verdadeiro positivo/falso positivo > qtd * (ltv - cac - cupom)
- Cálculo para falso negativo > qtd * cac
- Cálculo para verdadeiro negativo > qtd * (ltv - cac)
- Fórmula resultado > VP + VN + FP - FN

#Coleta e descrição dos dados
"""

#Importando as tabelas
df_cliente = pd.read_csv('/content/clientes.csv')
df_churn = pd.read_csv('/content/churn.csv')
df_dicionario_cliente = pd.read_excel('/content/Metadados.xlsx', sheet_name='clientes')
df_dicionario_churn = pd.read_excel('/content/Metadados.xlsx', sheet_name='churn')

#Analisando a descrição dos dados da tabela cliente
df_dicionario_cliente

#Analisando a descrição dos dados da tabela churn
df_dicionario_churn

#Verificando se o período de fato corresponde a 4 meses
df_churn['DataUltimaTransacao'] = pd.to_datetime(df_churn['DataUltimaTransacao'])
df_cliente['DataExtracao'] = pd.to_datetime(df_cliente['DataExtracao'])

df_churn['DataUltimaTransacao'].max() - df_cliente['DataExtracao'][0]

#Unindo as tabelas
df = pd.merge(df_cliente, df_churn[['ClientId', 'DataUltimaTransacao']], on='ClientId', how='left')

#Criando a coluna Churn=1
df['Dias'] =  (df['DataUltimaTransacao'].max() - df['DataUltimaTransacao']).dt.days
df['Churn'] = 0
df.loc[df['Dias'] > 30, 'Churn'] = 1

#Excluindo as colunas desnecessarias(utilizadas somente para classificar o churn)
df = df.drop(['DataExtracao','DataUltimaTransacao','Dias'], axis=1)

#Analisando a estrutura
df.info()

#Analisando as primeiras linhas
df.head()

#Verificação de valores inconsistentes(variáveis quantitativas)
df.describe()

#Verificação de valores inconsistentes(variáveis qualitativas)
df['Estado'].value_counts(),df['Gênero'].value_counts()

#Verificação de registros duplicados
df[df.duplicated(keep=False)]

#Dividindo a base em treino e teste(20%)
df_treino, df_teste = train_test_split(df, test_size=0.3, stratify=df['Churn'], random_state=42)
#Organizando os índices
df_treino.reset_index(drop=True, inplace=True)
df_teste.reset_index(drop=True, inplace=True)

"""#Análise exploratória

##Univariada
"""

#Analisando a variável Churn
qualitativa(df_treino['Churn'])

"""<font color="yellow" size="4">A percentual de churn de 20,1% está acima dos padrões de marcado.</font>"""

#Analisando a variável Estado
qualitativa(df_treino['Estado'])

#Analisando a variável Gênero
qualitativa(df_treino['Gênero'])

#Analisando a variável Qte_Categorias
qualitativa(df_treino['Qte_Categorias'])

"""<font color="yellow" size="4">Existe uma concentração de clientes que compraram até 2 categorias.</font>"""

#Analisando a variável Usa_Cartao_Credito
qualitativa(df_treino['Usa_Cartao_Credito'])

#Analisando a variável Programa_Fidelidade
qualitativa(df_treino['Programa_Fidelidade'])

#Analisando a variável Idade
quantitativa(df_treino['Idade'])

"""<font color="yellow" size="4">75% da base possui até 44 anos, porém há muitos outliers.</font>"""

#Analisando a Tempo_Cliente
quantitativa(df_treino['Tempo_Cliente'])

#Analisando a Score_Credito
quantitativa(df_treino['Score_Credito'])

#Analisando a Limite_Credito_Mercado
quantitativa(df_treino['Limite_Credito_Mercado'])

"""<font color="yellow" size="4">Apesar da base possuir bom score(variável Score_Credito), até 25% da base não possui crédito no mercado, o que pode indicar uma inconsistência.</font>"""

#Analisando a Sum_Pedidos_Acumulados
quantitativa(df_treino['Sum_Pedidos_Acumulados'])

"""##Bivariada"""

#Analisando associação entre Estado e Churn
Estado = tabela_iv(df_treino['Estado'],df_treino['Churn'])

"""<font color="yellow" size="4">O estado de Minas Gerais é o estado com a maior taxa de churn.</font>"""

#Analisando associação entre Gênero e Churn
Genero = tabela_iv(df_treino['Gênero'],df_treino['Churn'])

#Analisando associação entre Qte_Categorias e Churn
Qte_Categorias = tabela_iv(df_treino['Qte_Categorias'],df_treino['Churn'])

"""<font color="yellow" size="4">Clientes que compraram em 2 categorias possuem a menor taxa de churn(0,07%), em contrapartida, clientes que compraram acima de 2 categorias apresentaram uma taxa de churn muito superior. Uma hipótese levatada foi que algumas categorias podem estar sendo privilegiadas em relação as demais, por isso se faz necessário realizar uma análise mais apurada considerando também os tipos de categoria.</font>"""

#Analisando associação entre Usa_Cartao_Credito e Churn
Usa_Cartao_Credito = tabela_iv(df_treino['Usa_Cartao_Credito'],df_treino['Churn'])

#Analisando associação entre Programa_Fidelidade e Churn
Programa_Fidelidade = tabela_iv(df_treino['Programa_Fidelidade'],df_treino['Churn'])

"""<font color="yellow" size="4">Programas de fidelidade podem ser um bom incentivo a reduzir a taxa de Churn visto, porém é necessário analisar o potencial financeiro desses programas.</font>"""

#Analisando associação entre Idade e Churn
Idade = tabela_iv(df_treino['Idade'],df_treino['Churn'])

"""<font color="yellow" size="4">A idade possui forte poder de classificação quanto ao Churn. Clientes até 39 anos apresentam uma taxa de churn aceitável, porém a medida que a idade aumenta, a taxa também aumenta, ao ponto que clientes na faixa de 52 a 57 anos apresentam uma taxa de 58%, ou seja mais da metade dão Churn. Esse comportamento diminui quando a idade já é mais avançada, porém como há outliers é necessário análisar essa relação os excluindo.</font>"""

#Analisando associação entre Tempo_Cliente e Churn
Tempo_Cliente = tabela_iv(df_treino['Tempo_Cliente'],df_treino['Churn'])

#Analisando associação entre Score_Credito e Churn
Score_Credito = tabela_iv(df_treino['Score_Credito'],df_treino['Churn'])

#Analisando associação entre Limite_Credito_Mercado e Churn
Limite_Credito_Mercado = tabela_iv(df_treino['Limite_Credito_Mercado'],df_treino['Churn'])

"""<font color="yellow" size="4">Usuários com maior limite de crédito apresentam uma leve tendência em dar Churn</font>"""

#Analisando associação entre Sum_Pedidos_Acumulados e Churn
Sum_Pedidos_Acumulados = tabela_iv(df_treino['Sum_Pedidos_Acumulados'],df_treino['Churn'])

"""#Preparação dos dados

##Separando as bases em X e y
"""

#Fazendo uma cópia do df para iniciar a preparação dos dados
df_treino_prep = df_treino.copy()
df_teste_prep = df_teste.copy()

#Separando em variável explicativa e resposta
X = df_treino_prep.drop(['Churn','ClientId'], axis=1)
y = df_treino_prep['Churn']
X_teste = df_teste_prep.drop(['Churn','ClientId'], axis=1)
y_teste = df_teste_prep['Churn']

y.info()

"""##Tratando variáveis categóricas"""

#Alterando o tipo da variável Qte_categorias para ela se tornar dummie
X['Qte_Categorias'] = X['Qte_Categorias'].astype(str)
X_teste['Qte_Categorias'] = X_teste['Qte_Categorias'].astype(str)
#Codificando para adequar ao processamento do modelo
X = pd.get_dummies(X, drop_first=True)
X_teste = pd.get_dummies(X_teste, drop_first=True)

"""##Selecionando variáveis"""

#Selecionando com base no p-valor(Eliminação Stepwise)
model = sm.Logit(y, X)
result = model.fit()
result.pvalues.apply(lambda x: f"{x:.3f}")

#Excluindo as variáveis com p-valor alto
X = X.drop(['Sum_Pedidos_Acumulados','Usa_Cartao_Credito','Limite_Credito_Mercado'], axis=1)
#Rodando novamente o modelo
model = sm.Logit(y, X)
result = model.fit()
result.pvalues.apply(lambda x: f"{x:.3f}")

#Aplicando a transformação na base teste
X_teste = X_teste.drop(['Sum_Pedidos_Acumulados','Usa_Cartao_Credito','Limite_Credito_Mercado'], axis=1)

"""##Tratamento de outliers"""

#Encontrando os outliers da variável Idade
indices_outliers = outliers(X['Idade'],y)
#Excluindo os outliers
X = X.drop(indices_outliers)
y = y.drop(indices_outliers)
#Organizando os índices
X.reset_index(drop=True, inplace=True)
y.reset_index(drop=True, inplace=True)

#Verificando o novo IV
tabela_iv(X['Idade'],y)

"""<font color="yellow" size="4">O IV aumentou de 0.81 para 0.92 e ficou claro a forte tendência de Churn em clientes com idade mais avançada. Nas faixas a partir de 58 anos, todos clientes deram Churn.</font>

##Escalonamento(Min-Max Scaling)
"""

# Inicializar o scaler
scaler = MinMaxScaler()
# Treinar o scaler aos dados
colunas = ['Score_Credito', 'Idade', 'Tempo_Cliente']
scaler.fit(X[colunas])
# Aplicar em ambas bases
X[colunas] = scaler.transform(X[colunas])
X_teste[colunas] = scaler.transform(X_teste[colunas])

"""##Balanceamento(undersampler)"""

undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)
X, y = undersampler.fit_resample(X, y)

"""#Modelagem

##Treinando o modelo
"""

# Instanciando e configurando o modelo de regressão logística
modelo_regressao = LogisticRegression(random_state=42)

# Treinando o modelo
modelo_regressao.fit(X, y)

#Medindo a performance utilizando AUC

#Obtendo as probabilidades
y_proba = modelo_regressao.predict_proba(X)[:, 1]

# Calcula a área abaixo da curva ROC
auc = roc_auc_score(y, y_proba)

print(f'AUC da regressão logística: {auc:.2f}')

"""<font color="yellow">A métrica utilziada será o AUC, pois é a mais indicada quando trata-se de uma base desbalanceada.</font>

##Validação
"""

#Criando 5 dobras estratificadas
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Lista para armazenar os resultados
treino_aucs = []
validacao_aucs = []

# Realizando a validação cruzada estratificada
for treino_index, validacao_index in stratified_kfold.split(X, y):
    X_treino, X_validacao = X.iloc[treino_index], X.iloc[validacao_index]
    y_treino, y_validacao = y.iloc[treino_index], y.iloc[validacao_index]

    modelo_regressao.fit(X_treino, y_treino)

    y_train_pred = modelo_regressao.predict_proba(X_treino)[:, 1]
    y_validacao_pred = modelo_regressao.predict_proba(X_validacao)[:, 1]

    train_auc = roc_auc_score(y_treino, y_train_pred)
    validation_auc = roc_auc_score(y_validacao, y_validacao_pred)

    treino_aucs.append(train_auc)
    validacao_aucs.append(validation_auc)

#Calculando a média e desvio padrão
mean_train_auc = np.mean(treino_aucs)
mean_validation_auc = np.mean(validacao_aucs)
std_train_auc = np.std(treino_aucs)
std_validation_auc = np.std(validacao_aucs)

# Exibindo os resultados
for i, (treino_auc, validacao_auc) in enumerate(zip(treino_aucs, validacao_aucs), 1):
    print(f"Fold {i}: AUC (Treino) = {treino_auc:.4f}, AUC (Validação) = {validacao_auc:.4f}")

print(20*'-=')

print(f'Média AUC Treino: {mean_train_auc:.4f}')
print(f'Média AUC Validação: {mean_validation_auc:.4f}')
print(f'Desvio AUC Treino: {std_train_auc:.4f}')
print(f'Desvio AUC Validação: {std_validation_auc:.4f}')

"""<font color="yellow">Modelo consistente tanto na média quanto no desvio padrão dos AUC.</font>"""

# Instanciando e treinando o modelo final
modelo_final = LogisticRegression(random_state=42)
modelo_final.fit(X, y)

#Testando na base de teste
prob_teste = modelo_final.predict_proba(X_teste)[:,1]
roc_teste = roc_auc_score(y_teste, prob_teste)
print(f'AUC na base Teste: {roc_teste}')

"""<font color="yellow">AUC final ficou em 0.81,5</font>

#Medindo o impacto financeiro
"""

#Definindo as variáveis para o cálculo financeiro(vide premissas)
ltv = 419
cac = 150
cupom = 100

# Criando a função para calcular o lucro
def calcular_lucro(y_test, y_probs, threshold):
    y_pred = np.where(y_probs >= threshold, 1, 0)
    cm = confusion_matrix(y_test, y_pred)

    vn = cm[0,0] * (ltv - cac)
    fn = cm[1,0] * cac
    vp = cm[1,1] * (ltv-cac-cupom)
    fp = cm[0,1] * (ltv-cac-cupom)

    lucro_total = vn + vp + fp - fn

    return lucro_total

# Criando a função para encontrar o threshold ótimo
def encontrar_threshold_otimo(modelo, X_test, y_test):
    y_probs = modelo.predict_proba(X_test)[:, 1]

    thresholds = np.linspace(0, 1, 1000)
    lucros = []

    for threshold in thresholds:
        lucro = calcular_lucro(y_test, y_probs, threshold)
        lucros.append(lucro)

    threshold_otimo = thresholds[np.argmax(lucros)]

    return threshold_otimo

"""<font color="yellow">A intenção da função acima é otimizar o tempo, de forma que encontre automaticamente o threshold ótimo, que faça o modelo trabalhar para trazer o maior retorno financeiro.</font>"""

#Plotando a matriz de confusão considerando que ninguém dará churn(cenário atual), ou seja, não há modelo
y_predito_prob = modelo_final.predict_proba(X_teste)[:, 1]
y_predito = np.where(y_predito_prob >= 1.0, 1, 0)

# Calculando a matriz de confusão
cm = confusion_matrix(y_teste, y_predito)

#Plotando
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão sem uso do modelo - R$553.924,00')
plt.show()

#Calculando o resultado financeiro atual, sem o uso do modelo
receita_sem_modelo = calcular_lucro(y_teste, modelo_final.predict_proba(X_teste)[:, 1],1.0) #por o threshold em 100% equivale a não ter modelo
receita_sem_modelo

"""<font color="yellow">O resultado da empresa no período de 4 meses, sem o uso do modelo e sem o uso de qualquer regra, considerando 3000 clientes, foi de 553924 reais.</font>"""

#Calculando a matriz de confusão utilizando os insights da análise exploratória
#clientes com idade superior a 58 anos e 4 categorias compradas
y_predito = [1 if categoria >= 4 or idade >= 58 else 0 for categoria, idade in zip(df_teste['Qte_Categorias'], df_teste['Idade'])]

# Calculando a matriz de confusão
cm = confusion_matrix(y_teste, y_predito)

#Plotando
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão insights análise - R$562.754,00')
plt.show()

#Calculando o resultado financeiro utilizando somente a regra de idade e quantidade categorias
vn = cm[0,0] * (ltv - cac)
fn = cm[1,0] * cac
vp = cm[1,1] * (ltv-cac-cupom)
fp = cm[0,1] * (ltv-cac-cupom)

receita_analise = vn + vp + fp - fn
receita_analise - receita_sem_modelo

"""<font color="yellow">Considerando as mesmas condições, se fossem criadas regras baseadas na análise exploratória, na qual foi constatada a alta probabilidade de churn entre clientes com mais idade e clientes que compraram em 4 categorias, o ganho seria de 8830 reais em comparação ao resultado financeiro atual.</font>"""

# Calculando a matriz de confusão utilizando o modelo com threshold em 50%(padrão)
cm = confusion_matrix(y_teste, modelo_final.predict(X_teste))

#Plotando
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão com uso do modelo - R$635.812,00')
plt.show()

#Calculando o resultado financeiro que o modelo traria utilizando o threshold padrão(50%)
receita_modelo_padrao = calcular_lucro(y_teste, modelo_final.predict_proba(X_teste)[:, 1],0.5)
receita_modelo_padrao - receita_sem_modelo #diferença entre resultado com modelo e resultado sem modelo

"""<font color="yellow">Considerando as mesmas condições, se o modelo estivesse em produção, utilizando o threshold padrão(50%), a empresa teria um ganho de 81888 reais em comparação ao resultado financeiro atual.</font>"""

# Encontrando o threshold ótimo
encontrar_threshold_otimo(modelo_final,X_teste,y_teste)

# Calculando a matriz de confusão do modelo final com threshold ótimo(54%)
y_predito_prob = modelo_final.predict_proba(X_teste)[:, 1]
y_predito = np.where(y_predito_prob >= 0.54, 1, 0)

# Calculando a matriz de confusão
cm = confusion_matrix(y_teste, y_predito)

#Plotando
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão com threshold ótimo - R$638.589,00')
plt.show()

# Claculando o resultado financeiro que o modelo traria utilizando o threshold ótimo(54%)
receita_modelo_otimo = calcular_lucro(y_teste, modelo_final.predict_proba(X_teste)[:, 1],0.54)
receita_modelo_otimo - receita_sem_modelo #diferença entre resultado com modelo(threshold ótimo) e resultado sem modelo

"""<font color="yellow">Considerando as mesmas condições, se o modelo estivesse em produção, utilizando o threshold Ótimo(54%), a empresa teria um ganho de 84665 reais em comparação ao resultado financeiro atual. Esse valor representa uma diferença positiva de 2777 reais em comparação ao modelo com threshold padrão. </font>"""